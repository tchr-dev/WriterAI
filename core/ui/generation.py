import streamlit as st
import logging
from core.llm_handler import LLMHandler
from utils.config import load_config, save_config

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    filename="logs/llm.log",
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)


def log_interaction(prompt: str, response: str):
    logging.info("Prompt: %s", prompt)
    logging.info("Response: %s", response)


def generation_ui():
    st.title("üïãÔ∏è NovelCraft: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞")

    if "history" not in st.session_state:
        st.session_state.history = []

    config = load_config()
    default_model = config.get("model", "llama3")
    default_temp = config.get("temperature", 0.7)

    st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    model_choice = st.sidebar.selectbox("–ú–æ–¥–µ–ª—å", ["llama3", "mistral"], index=[
                                        "llama3", "mistral"].index(default_model))
    temperature = st.sidebar.slider(
        "–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å", 0.1, 1.0, float(default_temp))

    if st.sidebar.button("üîñ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"):
        save_config({"model": model_choice, "temperature": temperature})
        st.sidebar.success("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")

    user_text = st.text_area("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–µ–∫—Å—Ç:",
                             height=300, placeholder="–ù–∞—á–Ω–∏—Ç–µ –ø–∏—Å–∞—Ç—å –∑–¥–µ—Å—å...")

    if st.button("‚úçÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ"):
        if user_text.strip():
            with st.spinner("–ò–ò –¥—É–º–∞–µ—Ç..."):
                handler = LLMHandler(
                    model_name=f"ollama:{model_choice}",
                    temperature=temperature,
                    use_memory=True
                )

                generated_text = handler.generate_from_template(user_text)

                st.success("‚úÖ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ:")
                st.text_area("–û—Ç–≤–µ—Ç", value=generated_text, height=300)

                st.session_state.history.append({
                    "input": user_text,
                    "output": generated_text
                })

                log_interaction(user_text, generated_text)

                with st.expander("üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏"):
                    memory = handler.get_context_data()

                    st.subheader("üìò –°–≤–æ–¥–∫–∞ —Å—é–∂–µ—Ç–∞")
                    st.json(memory["summary"])

                    st.subheader("üë§ –ü–µ—Ä—Å–æ–Ω–∞–∂–∏")
                    st.json(memory["characters"])

                    st.subheader("üåç –õ–æ—Ä / –ú–∞–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞")
                    for item in memory["lore"]:
                        st.markdown(f"- {item}")
        else:
            st.warning("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")
