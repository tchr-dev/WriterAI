import streamlit as st
import logging
from core.llm_handler import LLMHandler
from core.prompts.prompt_editor import prompt_editor_ui
from core.lore.lore_editor import lore_editor_ui
from utils.config import load_config, save_config
from logger.log_writer import list_log_files, load_logs_from_file

st.set_page_config(page_title="NovelCraft MVP", layout="wide")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    filename="logs/llm.log",
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)


def log_interaction(prompt: str, response: str):
    logging.info("Prompt: %s", prompt)
    logging.info("Response: %s", response)


def generation_ui():
    st.title("üïãÔ∏è NovelCraft: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
    if "history" not in st.session_state:
        st.session_state.history = []

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = load_config()
    default_model = config.get("model", "llama3")
    default_temp = config.get("temperature", 0.7)

    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    model_choice = st.sidebar.selectbox("–ú–æ–¥–µ–ª—å", ["llama3", "mistral"], index=[
                                        "llama3", "mistral"].index(default_model))
    temperature = st.sidebar.slider(
        "–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å", 0.1, 1.0, float(default_temp))

    if st.sidebar.button("üîñ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"):
        save_config({"model": model_choice, "temperature": temperature})
        st.sidebar.success("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")

    # –í–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
    user_text = st.text_area("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–µ–∫—Å—Ç:", height=300,
                             placeholder="–ù–∞—á–Ω–∏—Ç–µ –ø–∏—Å–∞—Ç—å –∑–¥–µ—Å—å...")

    if st.button("‚úçÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ"):
        if user_text.strip():
            with st.spinner("–ò–ò –¥—É–º–∞–µ—Ç..."):
                handler = LLMHandler(
                    model_name=f"ollama:{model_choice}",
                    temperature=temperature,
                    use_memory=True  # –í–∫–ª—é—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –ø–∞–º—è—Ç—å
                )

                generated_text = handler.generate_from_template(user_text)

                st.success("‚úÖ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ:")
                st.text_area("–û—Ç–≤–µ—Ç", value=generated_text, height=300)

                st.session_state.history.append({
                    "input": user_text,
                    "output": generated_text
                })

                log_interaction(user_text, generated_text)

                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø–∞–º—è—Ç—å
                with st.expander("üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏"):
                    memory = handler.get_context_data()

                    st.subheader("üìò –°–≤–æ–¥–∫–∞ —Å—é–∂–µ—Ç–∞")
                    st.json(memory["summary"])

                    st.subheader("üë§ –ü–µ—Ä—Å–æ–Ω–∞–∂–∏")
                    st.json(memory["characters"])

                    st.subheader("üåç –õ–æ—Ä / –ú–∞–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞")
                    for item in memory["lore"]:
                        st.markdown(f"- {item}")
        else:
            st.warning("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π!")

    if st.checkbox("üïò –ü–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
        for i, item in enumerate(reversed(st.session_state.history), 1):
            st.markdown(f"**#{i} –ó–∞–ø—Ä–æ—Å:** {item['input']}")
            st.markdown(f"**–û—Ç–≤–µ—Ç:** {item['output']}")
            st.markdown("---")


def history_ui():
    st.title("üìú –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤")

    log_files = list_log_files()
    if log_files:
        selected_log = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –ª–æ–≥–∞", log_files, index=len(log_files)-1)
        logs = load_logs_from_file(selected_log)

        for entry in reversed(logs):
            with st.expander(f"{entry.get('timestamp', '–Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏')} | {entry.get('model_name', '–º–æ–¥–µ–ª—å?')}"):
                st.markdown(
                    f"**Prompt:**\n```text\n{entry.get('prompt', '')}```")
                st.markdown(
                    f"**Response:**\n```text\n{entry.get('response', '')}```")
    else:
        st.info("–§–∞–π–ª—ã –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")


def main():
    # –ù–∞–≤–∏–≥–∞—Ü–∏—è
    page = st.sidebar.selectbox("üìö –ù–∞–≤–∏–≥–∞—Ü–∏—è", [
        "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞", "üß† Prompt Editor", "üìú –ò—Å—Ç–æ—Ä–∏—è", "üåç –†–µ–¥–∞–∫—Ç–æ—Ä –õ–æ—Ä–∞"
    ])

    if page == "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞":
        generation_ui()
    elif page == "üß† Prompt Editor":
        prompt_editor_ui()
    elif page == "üìú –ò—Å—Ç–æ—Ä–∏—è":
        history_ui()
    elif page == "üåç –†–µ–¥–∞–∫—Ç–æ—Ä –õ–æ—Ä–∞":
        lore_editor_ui()


if __name__ == "__main__":
    main()
